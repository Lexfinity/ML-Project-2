{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "import decimal\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import stdev\n",
    "from statistics import mean\n",
    "import time\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoretWithModel(model, x_train, x_test, y_train, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    return model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comments</th>\n",
       "      <th>subreddits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Honestly, Buffalo is the correct answer. I rem...</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ah yes way could have been :( remember when he...</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>He wouldn't have been a bad signing if we woul...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Easy. You use the piss and dry technique. Let ...</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>69995</td>\n",
       "      <td>Thank you, you confirm Spain does have nice pe...</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>69996</td>\n",
       "      <td>Imagine how many he would have killed with a r...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>69997</td>\n",
       "      <td>Yes. Only. As in the guy I was replying to was...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>69998</td>\n",
       "      <td>Looking for something light-hearted or has a v...</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>69999</td>\n",
       "      <td>I love how I never cry about casters because I...</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           comments  \\\n",
       "0          0  Honestly, Buffalo is the correct answer. I rem...   \n",
       "1          1  Ah yes way could have been :( remember when he...   \n",
       "2          2  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...   \n",
       "3          3  He wouldn't have been a bad signing if we woul...   \n",
       "4          4  Easy. You use the piss and dry technique. Let ...   \n",
       "...      ...                                                ...   \n",
       "69995  69995  Thank you, you confirm Spain does have nice pe...   \n",
       "69996  69996  Imagine how many he would have killed with a r...   \n",
       "69997  69997  Yes. Only. As in the guy I was replying to was...   \n",
       "69998  69998  Looking for something light-hearted or has a v...   \n",
       "69999  69999  I love how I never cry about casters because I...   \n",
       "\n",
       "            subreddits  \n",
       "0               hockey  \n",
       "1                  nba  \n",
       "2      leagueoflegends  \n",
       "3               soccer  \n",
       "4                funny  \n",
       "...                ...  \n",
       "69995           europe  \n",
       "69996  leagueoflegends  \n",
       "69997           canada  \n",
       "69998            anime  \n",
       "69999  GlobalOffensive  \n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 1409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditDataTrain = pd.read_csv(\"data/reddit_train.csv\") #, sep=\"\\n\", header=None) \n",
    "redditDataTest = pd.read_csv(\"data/reddit_test.csv\") # sep=\"\\n\", header=None)\n",
    "redditDataTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsTrain = redditDataTrain.iloc[:,1]\n",
    "subredditsTrain = redditDataTrain.iloc[:,-1]\n",
    "commentsTest = redditDataTest.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "cv = CountVectorizer()\n",
    "lr = LogisticRegression()\n",
    "multiNB = MultinomialNB()\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "kf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=4)\n",
    "kf = KFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [],
   "source": [
    "GX_train, GX_test, Gy_train, Gy_test = train_test_split(commentsTrain, subredditsTrain, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [],
   "source": [
    "GX_train = commentsTrain[commentsTrain.index < np.percentile(commentsTrain.index, 80)].sort_index()\n",
    "Gy_train = subredditsTrain[subredditsTrain.index < np.percentile(subredditsTrain.index, 80)].sort_index()\n",
    "GX_test = commentsTrain[commentsTrain.index > np.percentile(commentsTrain.index, 80)].sort_index()\n",
    "Gy_test = subredditsTrain[subredditsTrain.index > np.percentile(subredditsTrain.index, 80)].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so I am splitting the global train data into Gtest and Gtrain. Then I use k-fold on Gtrain. in the k-fold I select the model that gives the best accuracy. Then I use that model, to predict the global thing. Ideally I should be using k-fold for validating which theory about the data is correct. Then train the validation theory, using the entire Gtrain and predict Gtest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get avg accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_acc_for_model(model):\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(GX_train, Gy_train):\n",
    "        x_train, x_test, y_train, y_test = GX_train[train_index], GX_train[test_index], Gy_train[train_index], Gy_train[test_index]\n",
    "        redditDataTrainTF = tfidf.fit_transform(x_train)\n",
    "        redditDataTestTF = tfidf.transform(x_test)\n",
    "        redditDataTrainTF.toarray()\n",
    "        clf = model()\n",
    "        results.append(getScoretWithModel(clf, redditDataTrainTF, redditDataTestTF, y_train, y_test))\n",
    "    avg_acc = sum(results)/len(results)\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression, MultinomialNB, tree.DecisionTreeClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for model <class 'sklearn.linear_model.logistic.LogisticRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514875\n",
      "test for model <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "0.5297857142857143\n",
      "test for model <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "0.31\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(\"test for model\", model)\n",
    "    print(get_avg_acc_for_model(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### retrain with the entire model and test final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5482857142857143\n"
     ]
    }
   ],
   "source": [
    "GX_train_idf = tfidf.fit_transform(GX_train)\n",
    "GX_test_idf = tfidf.transform(GX_test)\n",
    "lr = LogisticRegression()\n",
    "final_acc = getScoretWithModel(lr, GX_train_idf, GX_test_idf, Gy_train, Gy_test)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
