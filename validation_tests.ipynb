{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "import decimal\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import stdev\n",
    "from statistics import mean\n",
    "import time\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from models.naive_bayes import MultiNomialNB as CustomNaiveBayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScoretWithModel(model, x_train, x_test, y_train, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    return model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comments</th>\n",
       "      <th>subreddits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Honestly, Buffalo is the correct answer. I rem...</td>\n",
       "      <td>hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ah yes way could have been :( remember when he...</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>He wouldn't have been a bad signing if we woul...</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Easy. You use the piss and dry technique. Let ...</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>69995</td>\n",
       "      <td>Thank you, you confirm Spain does have nice pe...</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>69996</td>\n",
       "      <td>Imagine how many he would have killed with a r...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>69997</td>\n",
       "      <td>Yes. Only. As in the guy I was replying to was...</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>69998</td>\n",
       "      <td>Looking for something light-hearted or has a v...</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>69999</td>\n",
       "      <td>I love how I never cry about casters because I...</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           comments  \\\n",
       "0          0  Honestly, Buffalo is the correct answer. I rem...   \n",
       "1          1  Ah yes way could have been :( remember when he...   \n",
       "2          2  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...   \n",
       "3          3  He wouldn't have been a bad signing if we woul...   \n",
       "4          4  Easy. You use the piss and dry technique. Let ...   \n",
       "...      ...                                                ...   \n",
       "69995  69995  Thank you, you confirm Spain does have nice pe...   \n",
       "69996  69996  Imagine how many he would have killed with a r...   \n",
       "69997  69997  Yes. Only. As in the guy I was replying to was...   \n",
       "69998  69998  Looking for something light-hearted or has a v...   \n",
       "69999  69999  I love how I never cry about casters because I...   \n",
       "\n",
       "            subreddits  \n",
       "0               hockey  \n",
       "1                  nba  \n",
       "2      leagueoflegends  \n",
       "3               soccer  \n",
       "4                funny  \n",
       "...                ...  \n",
       "69995           europe  \n",
       "69996  leagueoflegends  \n",
       "69997           canada  \n",
       "69998            anime  \n",
       "69999  GlobalOffensive  \n",
       "\n",
       "[70000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditDataTrain = pd.read_csv(\"data/reddit_train.csv\") #, sep=\"\\n\", header=None) \n",
    "redditDataTest = pd.read_csv(\"data/reddit_test.csv\") # sep=\"\\n\", header=None)\n",
    "redditDataTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsTrain = redditDataTrain.iloc[:,1]\n",
    "subredditsTrain = redditDataTrain.iloc[:,-1]\n",
    "commentsTest = redditDataTest.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoothing factor 0.01\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', )\n",
    "cv = CountVectorizer()\n",
    "lr = LogisticRegression()\n",
    "multiNB = MultinomialNB()\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "cnb = CustomNaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GX_train, GX_test, Gy_train, Gy_test = train_test_split(commentsTrain, subredditsTrain, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GX_train = commentsTrain[commentsTrain.index < np.percentile(commentsTrain.index, 80)].sort_index()\n",
    "# Gy_train = subredditsTrain[subredditsTrain.index < np.percentile(subredditsTrain.index, 80)].sort_index()\n",
    "# GX_test = commentsTrain[commentsTrain.index > np.percentile(commentsTrain.index, 80)].sort_index()\n",
    "# Gy_test = subredditsTrain[subredditsTrain.index > np.percentile(subredditsTrain.index, 80)].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=4)\n",
    "def get_avg_acc_for_model(model, **kwargs):\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(GX_train, Gy_train):\n",
    "        x_train, x_test, y_train, y_test = GX_train[train_index], GX_train[test_index], Gy_train[train_index], Gy_train[test_index]\n",
    "        redditDataTrainTF = tfidf.fit_transform(x_train)\n",
    "        redditDataTestTF = tfidf.transform(x_test)\n",
    "        redditDataTrainTF.toarray()\n",
    "        clf = model(**kwargs)\n",
    "        results.append(getScoretWithModel(clf, redditDataTrainTF, redditDataTestTF, y_train, y_test))\n",
    "    avg_acc = sum(results)/len(results)\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5239464285714286"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', strip_accents='ascii', ngram_range=(1, 2))\n",
    "get_avg_acc_for_model(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words, strip_accents='ascii', ngram_range=(1, 1), lowercase=True, tokenizer = token.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5447142857142857\n"
     ]
    }
   ],
   "source": [
    "GX_train_idf = tfidf.fit_transform(GX_train)\n",
    "GX_test_idf = tfidf.transform(GX_test)\n",
    "clf = LogisticRegression()\n",
    "final_acc = getScoretWithModel(clf, GX_train_idf, GX_test_idf, Gy_train, Gy_test)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5370714285714285\n"
     ]
    }
   ],
   "source": [
    "GX_train_idf = tfidf.fit_transform(GX_train)\n",
    "GX_test_idf = tfidf.transform(GX_test)\n",
    "clf = MultinomialNB()\n",
    "final_acc = getScoretWithModel(clf, GX_train_idf, GX_test_idf, Gy_train, Gy_test)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40264285714285714\n"
     ]
    }
   ],
   "source": [
    "GX_train_idf = tfidf.fit_transform(GX_train)\n",
    "GX_test_idf = tfidf.transform(GX_test)\n",
    "clf = RandomForestClassifier()\n",
    "final_acc = getScoretWithModel(clf, GX_train_idf, GX_test_idf, Gy_train, Gy_test)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5430714285714285\n"
     ]
    }
   ],
   "source": [
    "GX_train_idf = tfidf.fit_transform(GX_train)\n",
    "GX_test_idf = tfidf.transform(GX_test)\n",
    "clf = LinearSVC()\n",
    "final_acc = getScoretWithModel(clf, GX_train_idf, GX_test_idf, Gy_train, Gy_test)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### best model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words, strip_accents='ascii', ngram_range=(1, 1), lowercase=True, tokenizer = token.tokenize)\n",
    "GX_train_idf = tfidf.fit_transform(GX_train)\n",
    "GX_test_idf = tfidf.transform(GX_test)\n",
    "clf = CustomNaiveBayes(smoothing_factor=0.1)\n",
    "final_acc = getScoretWithModel(clf, GX_train_idf, GX_test_idf, Gy_train, Gy_test)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 64893)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=stop_words, strip_accents='ascii', ngram_range=(1, 1), lowercase=True, tokenizer = token.tokenize)\n",
    "GX_train_idf = tfidf.fit_transform(GX_train)\n",
    "GX_train_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 901866)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words, strip_accents='ascii', ngram_range=(1, 2), lowercase=True, tokenizer = token.tokenize)\n",
    "GX_train_idf = tfidf.fit_transform(GX_train)\n",
    "GX_test_idf = tfidf.transform(GX_test)\n",
    "GX_train_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 700000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_selector = SelectKBest(chi2, k=700000)\n",
    "GX_train_idf_best = chi2_selector.fit_transform(GX_train_idf, Gy_train)\n",
    "GX_test_idf_best = chi2_selector.fit_transform(GX_test_idf, Gy_test)\n",
    "GX_test_idf_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faizank/Documents/courses/comp551/mini_project1/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05228571428571428\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "final_acc = getScoretWithModel(clf, GX_train_idf_best, GX_test_idf_best, Gy_train, Gy_test)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
